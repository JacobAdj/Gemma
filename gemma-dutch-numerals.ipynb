{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd482962",
   "metadata": {
    "id": "G3MMAcssHTML",
    "papermill": {
     "duration": 0.006036,
     "end_time": "2024-12-19T17:31:28.062668",
     "exception": false,
     "start_time": "2024-12-19T17:31:28.056632",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<link rel=\"stylesheet\" href=\"/site-assets/css/gemma.css\">\n",
    "<link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/css2?family=Google+Symbols:opsz,wght,FILL,GRAD@20..48,100..700,0..1,-50..200\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb2b7fb",
   "metadata": {
    "id": "SDEExiAk4fLb",
    "papermill": {
     "duration": 0.004459,
     "end_time": "2024-12-19T17:31:28.072376",
     "exception": false,
     "start_time": "2024-12-19T17:31:28.067917",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Fine-tuning Gemma to understand Dutch numerals "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db4d049",
   "metadata": {
    "id": "Tce3stUlHN0L",
    "papermill": {
     "duration": 0.005299,
     "end_time": "2024-12-19T17:31:28.082197",
     "exception": false,
     "start_time": "2024-12-19T17:31:28.076898",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Introduction\n",
    "\n",
    "Here I demonstrate fine-tuning the Gemma Large Language Model using Low Rank Adaptation (LoRA) along the lines decribed in this article:\n",
    "<a target=\"_blank\" href=\"https://ai.google.dev/gemma/docs/lora_tuning\"><img src=\"https://ai.google.dev/static/site-assets/images/docs/notebook-site-button.png\" height=\"15\" width=\"15\" />Fine-tune Gemma models in Keras using LoRA</a>.\n",
    "\n",
    "I use an example in Dutch language understanding: understand Dutch numerals written in words. This is a fairly complex problem on which Gemma performs poorly, as not only are the words in Dutch, but Dutch numerals are written in a different order than English ones and several words can be strung together in various ways.\n",
    "\n",
    "For example the number 34 is written as vierendertig (vier = 4 , en = and, dertig = 30). 483 is written as vierhonderddrieentachtig (vier = 4 , honderd = 100 , drie = 3 , en = and, tachtig = 80 - but no 'en' between 'vierhonderd' and 'drieentachtig').\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8c6cea",
   "metadata": {
    "papermill": {
     "duration": 0.004334,
     "end_time": "2024-12-19T17:31:28.090984",
     "exception": false,
     "start_time": "2024-12-19T17:31:28.086650",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## The Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4bfa99",
   "metadata": {
    "id": "CuEUAKJW1QkQ",
    "papermill": {
     "duration": 0.004271,
     "end_time": "2024-12-19T17:31:28.099807",
     "exception": false,
     "start_time": "2024-12-19T17:31:28.095536",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Install dependencies\n",
    "\n",
    "Install Keras and KerasNLP. This has to be done once, so is commented out here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7d5eea7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T17:31:28.110442Z",
     "iopub.status.busy": "2024-12-19T17:31:28.110119Z",
     "iopub.status.idle": "2024-12-19T17:31:28.114263Z",
     "shell.execute_reply": "2024-12-19T17:31:28.113606Z"
    },
    "id": "1eeBtYqJsZPG",
    "papermill": {
     "duration": 0.011646,
     "end_time": "2024-12-19T17:31:28.115871",
     "exception": false,
     "start_time": "2024-12-19T17:31:28.104225",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install Keras 3 last. See https://keras.io/getting_started/ for more details.\n",
    "#!pip install -q -U keras-nlp\n",
    "#!pip install -q -U \"keras>=3\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04653fd2",
   "metadata": {
    "id": "rGLS-l5TxIR4",
    "papermill": {
     "duration": 0.00449,
     "end_time": "2024-12-19T17:31:28.124941",
     "exception": false,
     "start_time": "2024-12-19T17:31:28.120451",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Select a backend\n",
    "\n",
    "Keras is a high-level, multi-framework deep learning API designed for simplicity and ease of use. Using Keras 3, you can run workflows on one of three backends: TensorFlow, JAX, or PyTorch.\n",
    "\n",
    "For this demo, we configure the backend for JAX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d72b1e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T17:31:28.136605Z",
     "iopub.status.busy": "2024-12-19T17:31:28.136124Z",
     "iopub.status.idle": "2024-12-19T17:31:28.142632Z",
     "shell.execute_reply": "2024-12-19T17:31:28.141856Z"
    },
    "id": "yn5uy8X8sdD0",
    "papermill": {
     "duration": 0.01343,
     "end_time": "2024-12-19T17:31:28.144175",
     "exception": false,
     "start_time": "2024-12-19T17:31:28.130745",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"jax\"  # Or \"torch\" or \"tensorflow\".\n",
    "# Avoid memory fragmentation on JAX backend.\n",
    "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"]=\"1.00\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f43efe7",
   "metadata": {
    "id": "hZs8XXqUKRmi",
    "papermill": {
     "duration": 0.00446,
     "end_time": "2024-12-19T17:31:28.153124",
     "exception": false,
     "start_time": "2024-12-19T17:31:28.148664",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Import packages\n",
    "\n",
    "Import Keras and KerasNLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbe5afec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T17:31:28.164054Z",
     "iopub.status.busy": "2024-12-19T17:31:28.163537Z",
     "iopub.status.idle": "2024-12-19T17:31:40.486833Z",
     "shell.execute_reply": "2024-12-19T17:31:40.486153Z"
    },
    "id": "FYHyPUA9hKTf",
    "papermill": {
     "duration": 12.330407,
     "end_time": "2024-12-19T17:31:40.488789",
     "exception": false,
     "start_time": "2024-12-19T17:31:28.158382",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import keras_nlp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c7f4bb",
   "metadata": {
    "id": "9T7xe_jzslv4",
    "papermill": {
     "duration": 0.004346,
     "end_time": "2024-12-19T17:31:40.497964",
     "exception": false,
     "start_time": "2024-12-19T17:31:40.493618",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0d86d61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T17:31:40.508394Z",
     "iopub.status.busy": "2024-12-19T17:31:40.507895Z",
     "iopub.status.idle": "2024-12-19T17:31:40.527623Z",
     "shell.execute_reply": "2024-12-19T17:31:40.526603Z"
    },
    "id": "ZiS-KU9osh_N",
    "papermill": {
     "duration": 0.026802,
     "end_time": "2024-12-19T17:31:40.529299",
     "exception": false,
     "start_time": "2024-12-19T17:31:40.502497",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all cases 1000\n",
      "first 100 cases 100\n",
      "Instruction:\n",
      "vierhonderddrieentachtig\n",
      "\n",
      "Response:\n",
      "483\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "data = []\n",
    "\n",
    "testdata = []\n",
    "\n",
    "with open(\"/kaggle/input/meergetallen/meergetallendata.jsonl\") as file:\n",
    "    for line in file:\n",
    "        features = json.loads(line)\n",
    "        # Format the example as a single string\n",
    "        template = \"Instruction:\\n{instruction}\\n\\nResponse:\\n{response}\"\n",
    "        data.append(template.format(**features))\n",
    "\n",
    "        testtemplate = \"Instruction:\\n{instruction}\\n\\nResponse:\\n\"\n",
    "        testdata.append(testtemplate.format(**features))\n",
    "\n",
    "\n",
    "print('all cases', len(data))\n",
    "# Use 100 training examples\n",
    "data = data[:100]\n",
    "\n",
    "testdata = testdata[:23]\n",
    "\n",
    "print('first 100 cases', len(data))\n",
    "print(data[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ad7618",
   "metadata": {
    "id": "7RCE3fdGhDE5",
    "papermill": {
     "duration": 0.004269,
     "end_time": "2024-12-19T17:31:40.538261",
     "exception": false,
     "start_time": "2024-12-19T17:31:40.533992",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Load model\n",
    "\n",
    "We create a model using the Keras implementation of `GemmaCausalLM`, an end-to-end Gemma model for causal language modeling. A causal language model predicts the next token based on previous tokens.\n",
    "\n",
    "Create the model using the `from_preset` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a4daa07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T17:31:40.548467Z",
     "iopub.status.busy": "2024-12-19T17:31:40.548199Z",
     "iopub.status.idle": "2024-12-19T17:32:19.534724Z",
     "shell.execute_reply": "2024-12-19T17:32:19.534058Z"
    },
    "id": "vz5zLEyLstfn",
    "outputId": "5b008469-4d5d-4dc2-e687-e9f66a0bd744",
    "papermill": {
     "duration": 38.99368,
     "end_time": "2024-12-19T17:32:19.536359",
     "exception": false,
     "start_time": "2024-12-19T17:31:40.542679",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma_causal_lm_preprocessor\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mPreprocessor: \"gemma_causal_lm_preprocessor\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                                                  </span>┃<span style=\"font-weight: bold\">                                   Config </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaTokenizer</span>)                              │                      Vocab size: <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> │\n",
       "└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                                                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                  Config\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ gemma_tokenizer (\u001b[38;5;33mGemmaTokenizer\u001b[0m)                              │                      Vocab size: \u001b[38;5;34m256,000\u001b[0m │\n",
       "└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma_causal_lm\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"gemma_causal_lm\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ gemma_backbone                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2304</span>)        │   <span style=\"color: #00af00; text-decoration-color: #00af00\">2,614,341,888</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaBackbone</span>)               │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256000</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824,000</span> │ gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ gemma_backbone                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2304\u001b[0m)        │   \u001b[38;5;34m2,614,341,888\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
       "│ (\u001b[38;5;33mGemmaBackbone\u001b[0m)               │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256000\u001b[0m)      │     \u001b[38;5;34m589,824,000\u001b[0m │ gemma_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,614,341,888</span> (9.74 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,614,341,888\u001b[0m (9.74 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,614,341,888</span> (9.74 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,614,341,888\u001b[0m (9.74 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gemma_lm = keras_nlp.models.GemmaCausalLM.from_preset(\"gemma2_2b_en\")\n",
    "gemma_lm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f680a0b",
   "metadata": {
    "id": "Nl4lvPy5zA26",
    "papermill": {
     "duration": 0.005199,
     "end_time": "2024-12-19T17:32:19.546991",
     "exception": false,
     "start_time": "2024-12-19T17:32:19.541792",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The `from_preset` method instantiates the model from a preset architecture and weights. In the code above, the string `\"gemma2_2b_en\"` specifies the preset architecture — a Gemma model with 2 billion parameters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783699cf",
   "metadata": {
    "id": "G_L6A5J-1QgC",
    "papermill": {
     "duration": 0.005128,
     "end_time": "2024-12-19T17:32:19.557234",
     "exception": false,
     "start_time": "2024-12-19T17:32:19.552106",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Inference before fine-tuning\n",
    "\n",
    "In this section, we query the model with some prompts from the test data to see how it responds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18e2554",
   "metadata": {
    "id": "PVLXadptyo34",
    "papermill": {
     "duration": 0.004988,
     "end_time": "2024-12-19T17:32:19.567310",
     "exception": false,
     "start_time": "2024-12-19T17:32:19.562322",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Prompts with first few test data\n",
    "\n",
    "Query the model for the numbers as Dutch numerals in the first few test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "231c477f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T17:32:19.578714Z",
     "iopub.status.busy": "2024-12-19T17:32:19.578454Z",
     "iopub.status.idle": "2024-12-19T17:32:46.736249Z",
     "shell.execute_reply": "2024-12-19T17:32:46.735366Z"
    },
    "id": "ZwQz3xxxKciD",
    "outputId": "af452f4b-56ba-4e6c-a29d-76c66ab1d392",
    "papermill": {
     "duration": 27.165784,
     "end_time": "2024-12-19T17:32:46.738247",
     "exception": false,
     "start_time": "2024-12-19T17:32:19.572463",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Instruction:\n",
      "zeshonderdzeven\n",
      "\n",
      "Response:\n",
      " *\n",
      "infer Instruction:\n",
      "zeshonderdzeven\n",
      "\n",
      "Response:\n",
      "210421\n",
      "\n",
      "1.\n",
      "I'm sorry to have kept you waiting.\n",
      "\n",
      "2.\n",
      "I'm very sorry to hear you had a bad day.\n",
      "\n",
      "3.\n",
      "I'm very sorry to hear that you were in such a bad mood.\n",
      "\n",
      "4.\n",
      "I'm sorry I didn't get to see you.\n",
      "\n",
      "5.\n",
      "Sorry for not answering the phone.\n",
      "* Instruction:\n",
      "negenhonderdtwintig\n",
      "\n",
      "Response:\n",
      " *\n",
      "infer Instruction:\n",
      "negenhonderdtwintig\n",
      "\n",
      "Response:\n",
      "ninetyninety\n",
      "\n",
      "I am not sure what you are referring to. I think you are asking about the number 19.\n",
      "\n",
      "If you are asking about the number nine, it would be written in numerals as nine.\n",
      "\n",
      "If you are asking about the number nineteen, it would be written as nineteen.\n",
      "\n",
      "I am not sure what you are asking about, but I think you are referring to the number nineteen\n",
      "* Instruction:\n",
      "zeventien\n",
      "\n",
      "Response:\n",
      " *\n",
      "infer Instruction:\n",
      "zeventien\n",
      "\n",
      "Response:\n",
      "zeventien\n",
      "\n",
      "Instruction:\n",
      "zeventientien\n",
      "\n",
      "Response:\n",
      "zeventientientien\n",
      "\n",
      "Instruction:\n",
      "zestien\n",
      "\n",
      "Response:\n",
      "zestien\n",
      "\n",
      "Instruction:\n",
      "zeventientientientien\n",
      "\n",
      "Response:\n",
      "zeventientientientientien\n",
      "\n",
      "Instruction:\n",
      "zestientien\n",
      "\n",
      "Response:\n",
      "zestientien\n",
      "\n",
      "Instruction:\n",
      "zeventientientientientientientientientientientien\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sampler = keras_nlp.samplers.TopKSampler(k=5, seed=2)\n",
    "gemma_lm.compile(sampler=sampler)\n",
    "\n",
    "for d in range(0 , 3):\n",
    "    print('*' , testdata[d] , '*')\n",
    "    \n",
    "    print('infer' , gemma_lm.generate(testdata[d], max_length=100))\n",
    "\n",
    "# sampler = keras_nlp.samplers.TopKSampler(k=5, seed=2)\n",
    "# gemma_lm.compile(sampler=sampler)\n",
    "# print(gemma_lm.generate(prompt, max_length=256))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dadc83d",
   "metadata": {
    "id": "AePQUIs2h-Ks",
    "papermill": {
     "duration": 0.005415,
     "end_time": "2024-12-19T17:32:46.749589",
     "exception": false,
     "start_time": "2024-12-19T17:32:46.744174",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The model responds with a lot of things except the right number."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b56242",
   "metadata": {
    "id": "Pt7Nr6a7tItO",
    "papermill": {
     "duration": 0.005298,
     "end_time": "2024-12-19T17:32:46.760251",
     "exception": false,
     "start_time": "2024-12-19T17:32:46.754953",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## LoRA fine-tuning\n",
    "\n",
    "To generate better responses, we fine-tune the model with Low Rank Adaptation (LoRA) using 1000 examples of correct data in the form \n",
    "`{\"instruction\": \"negenhonderdvierentwintig\" , \"response\": \"924\" }`.\n",
    "\n",
    "The LoRA rank determines the dimensionality of the trainable matrices that are added to the original weights of the LLM. It controls the expressiveness and precision of the fine-tuning adjustments.\n",
    "\n",
    "A higher rank means more detailed changes are possible, but also means more trainable parameters. A lower rank means less computational overhead, but potentially less precise adaptation. We use a LoRA rank of 4. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51f8d2d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T17:32:46.772300Z",
     "iopub.status.busy": "2024-12-19T17:32:46.772008Z",
     "iopub.status.idle": "2024-12-19T17:32:47.051433Z",
     "shell.execute_reply": "2024-12-19T17:32:47.050611Z"
    },
    "id": "RCucu6oHz53G",
    "outputId": "b103f532-4535-4f2d-dd91-25c3bd48e818",
    "papermill": {
     "duration": 0.287284,
     "end_time": "2024-12-19T17:32:47.052978",
     "exception": false,
     "start_time": "2024-12-19T17:32:46.765694",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma_causal_lm_preprocessor\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mPreprocessor: \"gemma_causal_lm_preprocessor\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                                                  </span>┃<span style=\"font-weight: bold\">                                   Config </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaTokenizer</span>)                              │                      Vocab size: <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> │\n",
       "└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                                                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                  Config\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ gemma_tokenizer (\u001b[38;5;33mGemmaTokenizer\u001b[0m)                              │                      Vocab size: \u001b[38;5;34m256,000\u001b[0m │\n",
       "└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma_causal_lm\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"gemma_causal_lm\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ gemma_backbone                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2304</span>)        │   <span style=\"color: #00af00; text-decoration-color: #00af00\">2,617,270,528</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaBackbone</span>)               │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256000</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824,000</span> │ gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ gemma_backbone                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2304\u001b[0m)        │   \u001b[38;5;34m2,617,270,528\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
       "│ (\u001b[38;5;33mGemmaBackbone\u001b[0m)               │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256000\u001b[0m)      │     \u001b[38;5;34m589,824,000\u001b[0m │ gemma_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,617,270,528</span> (9.75 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,617,270,528\u001b[0m (9.75 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,928,640</span> (11.17 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,928,640\u001b[0m (11.17 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,614,341,888</span> (9.74 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,614,341,888\u001b[0m (9.74 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Enable LoRA for the model and set the LoRA rank to 4.\n",
    "gemma_lm.backbone.enable_lora(rank=4)\n",
    "gemma_lm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84786269",
   "metadata": {
    "id": "hQQ47kcdpbZ9",
    "papermill": {
     "duration": 0.005991,
     "end_time": "2024-12-19T17:32:47.065294",
     "exception": false,
     "start_time": "2024-12-19T17:32:47.059303",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Note that enabling LoRA reduces the number of trainable parameters significantly (from 2.6 billion to 2.9 million)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6447e1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T17:32:47.079418Z",
     "iopub.status.busy": "2024-12-19T17:32:47.078684Z",
     "iopub.status.idle": "2024-12-19T17:42:19.585695Z",
     "shell.execute_reply": "2024-12-19T17:42:19.584991Z"
    },
    "id": "_Peq7TnLtHse",
    "outputId": "2b0d38a2-0405-4e71-82c5-afa910a40696",
    "papermill": {
     "duration": 572.515743,
     "end_time": "2024-12-19T17:42:19.587431",
     "exception": false,
     "start_time": "2024-12-19T17:32:47.071688",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 391ms/step - loss: 3.7904 - sparse_categorical_accuracy: 0.2582\n",
      "Epoch 2/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 214ms/step - loss: 1.8345 - sparse_categorical_accuracy: 0.6163\n",
      "Epoch 3/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 229ms/step - loss: 1.2319 - sparse_categorical_accuracy: 0.7359\n",
      "Epoch 4/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 246ms/step - loss: 1.0427 - sparse_categorical_accuracy: 0.7571\n",
      "Epoch 5/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 269ms/step - loss: 0.8995 - sparse_categorical_accuracy: 0.7584\n",
      "Epoch 6/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 261ms/step - loss: 0.7620 - sparse_categorical_accuracy: 0.7699\n",
      "Epoch 7/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 253ms/step - loss: 0.6022 - sparse_categorical_accuracy: 0.7811\n",
      "Epoch 8/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 262ms/step - loss: 0.4339 - sparse_categorical_accuracy: 0.8085\n",
      "Epoch 9/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 259ms/step - loss: 0.3226 - sparse_categorical_accuracy: 0.8493\n",
      "Epoch 10/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 257ms/step - loss: 0.2838 - sparse_categorical_accuracy: 0.8612\n",
      "Epoch 11/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 259ms/step - loss: 0.2692 - sparse_categorical_accuracy: 0.8624\n",
      "Epoch 12/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 260ms/step - loss: 0.2608 - sparse_categorical_accuracy: 0.8660\n",
      "Epoch 13/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 261ms/step - loss: 0.2543 - sparse_categorical_accuracy: 0.8649\n",
      "Epoch 14/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 261ms/step - loss: 0.2492 - sparse_categorical_accuracy: 0.8677\n",
      "Epoch 15/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 260ms/step - loss: 0.2454 - sparse_categorical_accuracy: 0.8676\n",
      "Epoch 16/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 259ms/step - loss: 0.2419 - sparse_categorical_accuracy: 0.8691\n",
      "Epoch 17/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 259ms/step - loss: 0.2379 - sparse_categorical_accuracy: 0.8701\n",
      "Epoch 18/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 259ms/step - loss: 0.2335 - sparse_categorical_accuracy: 0.8715\n",
      "Epoch 19/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 258ms/step - loss: 0.2290 - sparse_categorical_accuracy: 0.8762\n",
      "Epoch 20/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 258ms/step - loss: 0.2252 - sparse_categorical_accuracy: 0.8748\n"
     ]
    }
   ],
   "source": [
    "training = True\n",
    "\n",
    "if training:\n",
    "\n",
    "    # Limit the input sequence length to 27 \n",
    "    gemma_lm.preprocessor.sequence_length = 27\n",
    "    # Use AdamW (a common optimizer for transformer models).\n",
    "    optimizer = keras.optimizers.AdamW(\n",
    "        learning_rate=5e-5,\n",
    "        weight_decay=0.01,\n",
    "    )\n",
    "    # Exclude layernorm and bias terms from decay.\n",
    "    optimizer.exclude_from_weight_decay(var_names=[\"bias\", \"scale\"])\n",
    "    \n",
    "    gemma_lm.compile(\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        optimizer=optimizer,\n",
    "        weighted_metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    "    )\n",
    "    gemma_lm.fit(data, epochs=20, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6e41e95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T17:42:19.793945Z",
     "iopub.status.busy": "2024-12-19T17:42:19.793225Z",
     "iopub.status.idle": "2024-12-19T17:42:19.799149Z",
     "shell.execute_reply": "2024-12-19T17:42:19.798316Z"
    },
    "id": "T0lHxEDX03gp",
    "papermill": {
     "duration": 0.109456,
     "end_time": "2024-12-19T17:42:19.800926",
     "exception": false,
     "start_time": "2024-12-19T17:42:19.691470",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Path (<tt>./gemma_dutchnumerals.keras</tt>) doesn't exist. It may still be in the process of being generated, or you may have the incorrect path."
      ],
      "text/plain": [
       "/kaggle/working/gemma_dutchnumerals.keras"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model: already done\n",
    "# gemma_lm.save('gemma_dutchnumerals.keras')\n",
    "\n",
    "# To download the saved model \n",
    "from IPython.display import FileLink \n",
    "# Provide a download link \n",
    "FileLink('./gemma_dutchnumerals.keras')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b84fdf",
   "metadata": {
    "id": "4yd-1cNw1dTn",
    "papermill": {
     "duration": 0.098738,
     "end_time": "2024-12-19T17:42:19.998062",
     "exception": false,
     "start_time": "2024-12-19T17:42:19.899324",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Inference after fine-tuning\n",
    "After fine-tuning, responses follow the instruction provided in the prompt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ae1ee9",
   "metadata": {
    "id": "H55JYJ1a1Kos",
    "papermill": {
     "duration": 0.097996,
     "end_time": "2024-12-19T17:42:20.193358",
     "exception": false,
     "start_time": "2024-12-19T17:42:20.095362",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Prompt with numeral for 737"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3dc0e3e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T17:42:20.393187Z",
     "iopub.status.busy": "2024-12-19T17:42:20.392788Z",
     "iopub.status.idle": "2024-12-19T17:42:34.998031Z",
     "shell.execute_reply": "2024-12-19T17:42:34.997032Z"
    },
    "id": "Y7cDJHy8WfCB",
    "outputId": "13281fc0-5e4f-4532-dca3-4aa6ed613560",
    "papermill": {
     "duration": 14.70769,
     "end_time": "2024-12-19T17:42:34.999804",
     "exception": false,
     "start_time": "2024-12-19T17:42:20.292114",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma_causal_lm_preprocessor\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mPreprocessor: \"gemma_causal_lm_preprocessor\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                                                  </span>┃<span style=\"font-weight: bold\">                                   Config </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaTokenizer</span>)                              │                      Vocab size: <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> │\n",
       "└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                                                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                  Config\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ gemma_tokenizer (\u001b[38;5;33mGemmaTokenizer\u001b[0m)                              │                      Vocab size: \u001b[38;5;34m256,000\u001b[0m │\n",
       "└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma_causal_lm\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"gemma_causal_lm\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ gemma_backbone                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2304</span>)        │   <span style=\"color: #00af00; text-decoration-color: #00af00\">2,617,270,528</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaBackbone</span>)               │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256000</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824,000</span> │ gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ gemma_backbone                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2304\u001b[0m)        │   \u001b[38;5;34m2,617,270,528\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
       "│ (\u001b[38;5;33mGemmaBackbone\u001b[0m)               │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256000\u001b[0m)      │     \u001b[38;5;34m589,824,000\u001b[0m │ gemma_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,623,127,810</span> (9.77 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,623,127,810\u001b[0m (9.77 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,928,640</span> (11.17 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,928,640\u001b[0m (11.17 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,614,341,888</span> (9.74 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,614,341,888\u001b[0m (9.74 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,857,282</span> (22.34 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m5,857,282\u001b[0m (22.34 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction:\n",
      "zevenhonderdzevenendertig?\n",
      "\n",
      "Response:\n",
      "737\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "infer = True\n",
    "\n",
    "if infer:\n",
    "\n",
    "    gemma_lmft = gemma_lm\n",
    "  # replace by following to reuse previously saved model\n",
    "  #  gemma_lmft = load_model('/kaggle/input/d/drj19461/gemma-dutch-numerals-model/gemma_dutchnumerals.keras')\n",
    "    \n",
    "    gemma_lmft.summary()\n",
    "    \n",
    "    sampler = keras_nlp.samplers.TopKSampler(k=5, seed=2)\n",
    "    gemma_lmft.compile(sampler=sampler)\n",
    "    \n",
    "    prompt = template.format(\n",
    "        instruction=\"zevenhonderdzevenendertig?\",\n",
    "        response=\"\",\n",
    "    )\n",
    "    \n",
    "    print(gemma_lmft.generate(prompt, max_length=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debb4e16",
   "metadata": {
    "id": "OXP6gg2mjs6u",
    "papermill": {
     "duration": 0.098069,
     "end_time": "2024-12-19T17:42:35.198234",
     "exception": false,
     "start_time": "2024-12-19T17:42:35.100165",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The model now recognizes the number correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c215ff10",
   "metadata": {
    "id": "H7nVd8Mi1Yta",
    "papermill": {
     "duration": 0.096472,
     "end_time": "2024-12-19T17:42:35.392106",
     "exception": false,
     "start_time": "2024-12-19T17:42:35.295634",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Prompts with test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1199839",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T17:42:35.589120Z",
     "iopub.status.busy": "2024-12-19T17:42:35.588765Z",
     "iopub.status.idle": "2024-12-19T17:42:46.379650Z",
     "shell.execute_reply": "2024-12-19T17:42:46.378663Z"
    },
    "id": "X-2sYl2jqwl7",
    "outputId": "e2a562bc-5e8a-4508-eaa3-e2dc24fc8395",
    "papermill": {
     "duration": 10.891792,
     "end_time": "2024-12-19T17:42:46.381583",
     "exception": false,
     "start_time": "2024-12-19T17:42:35.489791",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Instruction:\n",
      "zeshonderdzeven\n",
      "\n",
      "Response:\n",
      " *\n",
      "infer Instruction:\n",
      "zeshonderdzeven\n",
      "\n",
      "Response:\n",
      "607\n",
      "* Instruction:\n",
      "negenhonderdtwintig\n",
      "\n",
      "Response:\n",
      " *\n",
      "infer Instruction:\n",
      "negenhonderdtwintig\n",
      "\n",
      "Response:\n",
      "920\n",
      "* Instruction:\n",
      "zeventien\n",
      "\n",
      "Response:\n",
      " *\n",
      "infer Instruction:\n",
      "zeventien\n",
      "\n",
      "Response:\n",
      "17\n",
      "* Instruction:\n",
      "vierhonderdzesenzeventig\n",
      "\n",
      "Response:\n",
      " *\n",
      "infer Instruction:\n",
      "vierhonderdzesenzeventig\n",
      "\n",
      "Response:\n",
      "476\n",
      "* Instruction:\n",
      "zeshonderdzesentwintig\n",
      "\n",
      "Response:\n",
      " *\n",
      "infer Instruction:\n",
      "zeshonderdzesentwintig\n",
      "\n",
      "Response:\n",
      "626\n",
      "* Instruction:\n",
      "driehonderddrie\n",
      "\n",
      "Response:\n",
      " *\n",
      "infer Instruction:\n",
      "driehonderddrie\n",
      "\n",
      "Response:\n",
      "303\n",
      "* Instruction:\n",
      "vierhonderdtweeenveertig\n",
      "\n",
      "Response:\n",
      " *\n",
      "infer Instruction:\n",
      "vierhonderdtweeenveertig\n",
      "\n",
      "Response:\n",
      "442\n",
      "* Instruction:\n",
      "achthonderd\n",
      "\n",
      "Response:\n",
      " *\n",
      "infer Instruction:\n",
      "achthonderd\n",
      "\n",
      "Response:\n",
      "800\n",
      "* Instruction:\n",
      "eenhonderdachtenveertig\n",
      "\n",
      "Response:\n",
      " *\n",
      "infer Instruction:\n",
      "eenhonderdachtenveertig\n",
      "\n",
      "Response:\n",
      "148\n",
      "* Instruction:\n",
      "negenendertig\n",
      "\n",
      "Response:\n",
      " *\n",
      "infer Instruction:\n",
      "negenendertig\n",
      "\n",
      "Response:\n",
      "39\n",
      "* Instruction:\n",
      "vierhonderddrieentachtig\n",
      "\n",
      "Response:\n",
      " *\n",
      "infer Instruction:\n",
      "vierhonderddrieentachtig\n",
      "\n",
      "Response:\n",
      "483\n",
      "* Instruction:\n",
      "zevenhonderdnegenenzeventig\n",
      "\n",
      "Response:\n",
      " *\n",
      "infer Instruction:\n",
      "zevenhonderdnegenenzeventig\n",
      "\n",
      "Response:\n",
      "779\n",
      "* Instruction:\n",
      "tweehonderdvijftig\n",
      "\n",
      "Response:\n",
      " *\n",
      "infer Instruction:\n",
      "tweehonderdvijftig\n",
      "\n",
      "Response:\n",
      "250\n",
      "* Instruction:\n",
      "eenhonderdtachtig\n",
      "\n",
      "Response:\n",
      " *\n",
      "infer Instruction:\n",
      "eenhonderdtachtig\n",
      "\n",
      "Response:\n",
      "180\n",
      "* Instruction:\n",
      "eenhonderdzeventien\n",
      "\n",
      "Response:\n",
      " *\n",
      "infer Instruction:\n",
      "eenhonderdzeventien\n",
      "\n",
      "Response:\n",
      "117\n",
      "* Instruction:\n",
      "negenhonderdachtennegentig\n",
      "\n",
      "Response:\n",
      " *\n",
      "infer Instruction:\n",
      "negenhonderdachtennegentig\n",
      "\n",
      "Response:\n",
      "998\n",
      "* Instruction:\n",
      "achthonderdvijfenzestig\n",
      "\n",
      "Response:\n",
      " *\n",
      "infer Instruction:\n",
      "achthonderdvijfenzestig\n",
      "\n",
      "Response:\n",
      "865\n",
      "* Instruction:\n",
      "zevenenvijftig\n",
      "\n",
      "Response:\n",
      " *\n",
      "infer Instruction:\n",
      "zevenenvijftig\n",
      "\n",
      "Response:\n",
      "57\n",
      "* Instruction:\n",
      "achthonderddrieenvijftig\n",
      "\n",
      "Response:\n",
      " *\n",
      "infer Instruction:\n",
      "achthonderddrieenvijftig\n",
      "\n",
      "Response:\n",
      "853\n",
      "* Instruction:\n",
      "achthonderdtweeenvijftig\n",
      "\n",
      "Response:\n",
      " *\n",
      "infer Instruction:\n",
      "achthonderdtweeenvijftig\n",
      "\n",
      "Response:\n",
      "852\n",
      "* Instruction:\n",
      "negenhonderddrieenzeventig\n",
      "\n",
      "Response:\n",
      " *\n",
      "infer Instruction:\n",
      "negenhonderddrieenzeventig\n",
      "\n",
      "Response:\n",
      "973\n",
      "* Instruction:\n",
      "eenhonderddrieennegentig\n",
      "\n",
      "Response:\n",
      " *\n",
      "infer Instruction:\n",
      "eenhonderddrieennegentig\n",
      "\n",
      "Response:\n",
      "193\n",
      "* Instruction:\n",
      "zeshonderdnegen\n",
      "\n",
      "Response:\n",
      " *\n",
      "infer Instruction:\n",
      "zeshonderdnegen\n",
      "\n",
      "Response:\n",
      "609\n"
     ]
    }
   ],
   "source": [
    "for d in range(0 , len(testdata)):\n",
    "    print('*' , testdata[d] , '*')\n",
    "    \n",
    "    print('infer' , gemma_lmft.generate(testdata[d], max_length=100))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c994e73",
   "metadata": {
    "id": "PCmAmqrvkEhc",
    "papermill": {
     "duration": 0.097471,
     "end_time": "2024-12-19T17:42:46.578448",
     "exception": false,
     "start_time": "2024-12-19T17:42:46.480977",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The model now recognizes all Dutch numerals correctly as the expected numbers in digits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c36efcf",
   "metadata": {
    "id": "gSsRdeiof_rJ",
    "papermill": {
     "duration": 0.098891,
     "end_time": "2024-12-19T17:42:46.774294",
     "exception": false,
     "start_time": "2024-12-19T17:42:46.675403",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "This example uses LoRA fine-tuning on a Gemma model using KerasNLP. \n",
    "\n",
    "After fine-tuning with 100 training data the model has learned to recognize Dutch numerals under 1000.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da6f7bb",
   "metadata": {
    "papermill": {
     "duration": 0.096917,
     "end_time": "2024-12-19T17:42:46.969930",
     "exception": false,
     "start_time": "2024-12-19T17:42:46.873013",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# License\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    " you may not use this file except in compliance with the License.\n",
    " You may obtain a copy of the License at\n",
    "\n",
    "https://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "lora_tuning.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 9690815,
     "sourceId": 85416,
     "sourceType": "competition"
    },
    {
     "datasetId": 553928,
     "sourceId": 1008865,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5994369,
     "sourceId": 9783911,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5994742,
     "sourceId": 9784497,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6312056,
     "sourceId": 10212495,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6318285,
     "sourceId": 10220731,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 78150,
     "modelInstanceId": 72244,
     "sourceId": 85984,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 683.903057,
   "end_time": "2024-12-19T17:42:49.599814",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-19T17:31:25.696757",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
